{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "仿照gym的形式进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rlcard.envs.registration import register, make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于make的调用 见test_registration.py  \n",
    "环境注册的入口位于：rlcard/envs/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env = make('no-limit-holdem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始状态: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 2.]\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print('初始状态:',state[0]['obs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'legal_actions': [0, 2, 3, 4, 5], 'obs': array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 2.])}, 1)\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(state)\n",
    "print(type(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于state的解读  \n",
    "state是一个tuple  \n",
    "第一维是一个数组：包含legal_actions obs   \n",
    "第二维代表当前玩家id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试一下内置一个random agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.首先在rlcard/models里面完善一个随机智能体  \n",
    "2.在环境nolimitholdem.py中完善函数load_model  \n",
    "3.在rlcard\\models\\_init_.py中进行注册 名称：'nolimit-holdem-random'  \n",
    "4.在nolimitholdem.py中通过函数_load_model引入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------模型载入成功----------------\n"
     ]
    }
   ],
   "source": [
    "env = make('no-limit-holdem',config={'single_agent_mode':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "接下来要解决的问题 如果现在内置了智能体 每次step返回的应该都是己方了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single agent mode下的reset state： {'legal_actions': [0, 2, 3, 4, 5], 'obs': array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 2.]), 'raw_obs': {'hand': ['SQ', 'S6'], 'public_cards': [], 'all_chips': [1, 2], 'my_chips': 1, 'legal_actions': [<Action.FOLD: 0>, <Action.CALL: 2>, <Action.RAISE_HALF_POT: 3>, <Action.RAISE_POT: 4>, <Action.ALL_IN: 5>], 'stakes': [99, 98], 'current_player': 0, 'pot': 3, 'stage': <Stage.PREFLOP: 0>}, 'raw_legal_actions': [<Action.FOLD: 0>, <Action.CALL: 2>, <Action.RAISE_HALF_POT: 3>, <Action.RAISE_POT: 4>, <Action.ALL_IN: 5>]}\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print('single agent mode下的reset state：',state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "state分析： 返回的是一个数组  \n",
    "legal_actions  \n",
    "obs  \n",
    "raw_obs 即文字版的 便于规则AI使用  \n",
    "raw_legal_action 文字版的 便于规则AI使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dealer id即小盲注位置为: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"dealer id即小盲注位置为:\",env.game.dealer_id)\n",
    "#目前env.game还没调研过\n",
    "#print(\"当前玩家为：\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选择的动作为: 0\n"
     ]
    }
   ],
   "source": [
    "action = np.random.choice(state['legal_actions'])\n",
    "print('选择的动作为:',action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果是在single agent的情况下 step函数返回的是   self._single_agent_step(action)  \n",
    "即next_state reward done  \n",
    "其中该另一玩家的动作已经在函数内部执行完了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next_state: {'legal_actions': [0, 2, 3, 4, 5], 'obs': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 1., 2.]), 'raw_obs': {'hand': ['CA', 'C2'], 'public_cards': [], 'all_chips': [1, 2], 'my_chips': 1, 'legal_actions': [<Action.FOLD: 0>, <Action.CALL: 2>, <Action.RAISE_HALF_POT: 3>, <Action.RAISE_POT: 4>, <Action.ALL_IN: 5>], 'stakes': [99, 98], 'current_player': 0, 'pot': 3, 'stage': <Stage.PREFLOP: 0>}, 'raw_legal_actions': [<Action.FOLD: 0>, <Action.CALL: 2>, <Action.RAISE_HALF_POT: 3>, <Action.RAISE_POT: 4>, <Action.ALL_IN: 5>]}\n",
      "reweard: 2\n",
      "done: True\n"
     ]
    }
   ],
   "source": [
    "state,reward,done = env.step(action)\n",
    "print('next_state:',state)\n",
    "print('reweard:',reward)\n",
    "print('done:',done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: 2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: 6\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: 100\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -6.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: 100\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -4.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -12.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -4.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: 8.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: 100.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: 2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -100\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: 100.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: 4\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: 100\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -1\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -4.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -1\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -1\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: 2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -6.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -32.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -100\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: 6.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: 2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -1\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -100.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: 2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -100.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -1\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -1\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: 2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: 2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -100\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: 2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -2\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: -100\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: 12.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -1\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 1\n",
      "current_id: 0\n",
      "累计reward: 4\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -100.0\n",
      "---------------new game------------------------\n",
      "dealer id即小盲注位置为: 0\n",
      "current_id: 0\n",
      "累计reward: -1\n"
     ]
    }
   ],
   "source": [
    "from rlcard.envs.registration import register, make\n",
    "import numpy as np\n",
    "for _ in range(50):\n",
    "    env = make('no-limit-holdem',config={'single_agent_mode':True})\n",
    "    print('---------------new game------------------------')\n",
    "    state = env.reset()\n",
    "    print(\"dealer id即小盲注位置为:\",env.game.dealer_id)\n",
    "    print('current_id:' , state['raw_obs']['current_player'])\n",
    "    #print('state:',state)\n",
    "    Reward = 0\n",
    "    while True:\n",
    "        action = np.random.choice(state['legal_actions'])\n",
    "        #print('选择的动作为:',action)\n",
    "        state,reward,done = env.step(action)\n",
    "        #print('state:',state)\n",
    "        #print('reweard:',reward)\n",
    "        #print('done:',done)\n",
    "        Reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    print('累计reward:',Reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlcard.models.CardEvaluator.lookup import Lookup\n",
    "lookup = Lookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hand_strength_band_high = -100\n",
    "hand_strength_band_low = -300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-166.75454545454875\n"
     ]
    }
   ],
   "source": [
    "hand = ['2c', '7h']\n",
    "board = ['5c', '4c', 'Ac', '6c', 'Qc']\n",
    "hand_strength = lookup.calc(hand, board)\n",
    "print(hand_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlcard",
   "language": "python",
   "name": "rlcard"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
